# dwtools
```{r init.tech, echo = FALSE}
knitr::opts_chunk$set(collapse=TRUE,comment="#>",fig.path="README-",cache=FALSE)
# knitr::knit("dwtools/README.Rmd","dwtools/README.md")
```
**Current version: pre 1.0.0**  

Data Warehouse tools. Extension for `data.table` package for Data Warehouse related functionalities.  
See below for core functions in the package.  
Report any bug as issues on github.

## Installation
```{r installation, eval=FALSE}
devtools::install_github("jangorecki/dwtools")
```

## Core functions
```{r init, results='hide'}
library(dwtools)
options("dwtools.verbose" = 0) # 1+ for status message
```

### dw.populate
Not core function but it will populate data for the next examples.  
`?dw.populate`
```{r dw.populate}
X = dw.populate(scenario="star schema")
SALES = X$SALES
GEOGRAPHY = X$GEOGRAPHY
head(SALES)
head(GEOGRAPHY)
```

### db
Function provides simple database interface.  
It handles DBI drivers (tested on Postgres and SQLite), RODBC (any odbc connection, not yet tested) and csv files as tables.  
NoSQL couchdb support in dev.  
In ETL terms where `data.table` serves as **Transformation** layer, the dwtools `db` function serves **Extraction** and **Loading** layers.  
`?db`
```{r db, results='hide'}
# setup db connections
library(RSQLite) # install.packages("RSQLite")
sqlite1 = list(drvName="SQLite",dbname="sqlite1.db",conn=dbConnect(SQLite(), dbname="sqlite1.db"))
options("dwtools.db.conns" = list(sqlite1=sqlite1, csv1=list(drvName="csv")))

# write to db (default connection)
db(SALES,"sales_table")
# read from from db
db("sales_table")
# query from db # not supported for csv driver
db("SELECT * FROM sales_table")
# send to db # not supported for csv driver
db("DROP TABLE sales_table")

# write geography data.table into multiple connections
db(GEOGRAPHY,"geography",c("sqlite1","csv1"))
# lookup from db and setkey
db("geography",key="state_code")
# use data.table chaining
SALES[,.(amount=sum(amount),value=sum(value)),keyby=list(state_code,date_code) # aggr to state_code, date_code
      ][,db("geography",key="state_code")[.SD] # lookup from sqlite1
        ][,.(amount=sum(amount),value=sum(value)),keyby=list(division_name,date_code) # aggr to division_code, date_code
          ]
SALES[,.SD,keyby=list(state_code) # setkey
      ][db("geography","csv1",key="state_code" # join to geography from csv file
           )[division_name=="East South Central" # filter geography to one division_name
             ], nomatch=0 # inner join
        ]
```
`db` function accepts vector of sql statements / table names to allow batch processing.  
In case of tables migration see `?dbCopy`.

### joinbyv
Denormalization of star schema and snowflake schema to flat fact table.  
`?joinbyv`
```{r joinbyv}
names(X) # list tables in star schema
sapply(X, nrow) # nrow of each tbl
# denormalize 
DT = joinbyv(
  master = X$SALES,
  join = list(customer = X$CUSTOMER,
              product = X$PRODUCT,
              geography = X$GEOGRAPHY,
              time = X$TIME,
              currency = X$CURRENCY),
  col.subset = list(c("cust_active"),
                    c("prod_group_name","prod_family_name"),
                    c("region_name"),
                    c("month_name"),
                    NULL)
  )
print(names(DT))
```

### CJI
Also known as *Nth setkey*.  
Creates custom indices for a data.table object. May require lot of memory.  
```{r CJI, results='hide'}
# not yet ready
# CJI()
```

## License
GPL-3.  
Donations are welcome and will be partially forwarded to dependencies of dwtools.  
[19JRajumtMNU9h9Wvdpsnq13SRdZjfbLeN](https://blockchain.info/address/19JRajumtMNU9h9Wvdpsnq13SRdZjfbLeN)

## Contact
`J.Gorecki@wit.edu.pl`
```{r exit_cleanup, echo=FALSE, results='hide'}
dbDisconnect(conn=sqlite1$conn)
file.remove(c("sqlite1.db","geography.csv"))
```